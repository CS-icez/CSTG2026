# Author users
INSERT INTO usr (name, gender, email, passwd, image_name, type, profile) VALUES
    ('Shengtian Qiao', 'M', 'stq0102@gmail.com', '123456', '1.jpg', 'A', 'I am an associate professor in the Peking University. My research interests includes computer networks, distributed systems, and wireless sensor networks.'),
    ('Zisu Bai', 'M', 'zissu@gmail.com', '234567', '2.jpg', 'A', 'I am a undergraduate student in the Peking University. My research interests include computer vision, machine learning, and natural language processing.'),
    ('Zhihao Zhang', 'M', 'hao@gmail.com', '345678', '3.jpg', 'A', 'I am a undergraduate student in the Tsinghua University. My research interests include computer graphics, computer vision, and machine learning.'),
    ('Mingyu Gao', 'M', 'clodhac@gmail.com', '456789', '4.jpg', 'A', 'I am an assistant professor in the Tsinghua University. My research interests include computer networks, distributed systems, and wireless sensor networks.'),
    ('Wit Hewen', 'M', 'waithw@gmail.com', '567890', '5.jpg', 'A', 'I am a graduate student in the UC Berkeley. My research interests include cryptography, computer security, and distributed systems.'),
    ('Bowen Liu', 'M', 'bowen111@gmail.com', '678901', '6.jpg', 'A', 'I am an engineer in the Google. My research interests include computer networks and distributed systems'),
    ('Manman Xiao', 'F', 'slow0323@gmail.com', '789012', '7.jpg', 'A', 'I am a undergraduate student in the Peking University. My research interests include natural language processing, machine learning, and computer vision.'),
    ('Lady Xiang', 'F', 'xianglady@gmail.com', '890123', '8.jpg', 'A', 'I am a graduate student in the UCLA. My research interests include TCS, algorithms, and complexity theory.'),
    ('Xinnv Zi', 'F', 'confident@gmail.com', '901234', '9.jpg', 'A', 'I am a undergraduate student in the Peking University. My research interests include robotics, computer vision, and machine learning.');

# Reviewer users
INSERT INTO usr (name, gender, email, passwd, image_name, type, profile) VALUES
    ('Kai', 'M', 'kai001@gmail.com', '1234567', '10.jpg', 'R', 'I am an associate professor in the Peking University. My research interests includes computer networks, social networks, and wireless sensor networks.'),
    ('Tianren Li', 'M', 'ltr@gmail.com', '2345678', '11.jpg', 'R', 'I am an assistant professor in the Peking University(soon to leave). My research interests include cryptography and computer security.'),
    ('Peixi Liu', 'M', 'lpx@gmail.com', '3456789', '12.jpg', 'R', 'I am a professor in the mathematics department of the Peking University.'),
    ('Wenfei Hu', 'M', 'huorwu@gmail.com', '4567890', '13.jpg', 'R', 'I am an assistant professor in the Tsinghua University. My research interests include computer networks, distributed systems, and wireless sensor networks.'),
    ('Teacher Xiang', 'M', 'teacher@gmail.com', '5678901', '14.jpg', 'R', 'I am an assistant professor in the Tsinghua University.'),
    ('Lvyan Li', 'F', 'greenswallow@gmail.com', '6789012', '15.jpg', 'R', 'I am a professor in the AI department of the Peking University. My research interest is database.'),
    ('Peter Irving', 'F', 'pirving@gmail.com', '7890123', '16.jpg', 'R', 'I am an engineer working in the Hunyuan Xingyi Taiji.'),
    ('Master Ma', 'F', 'cheat@gmail.com', '8901234', '17.jpg', 'R', 'Founder of the Hunyuan Xingyi Taiji. I am a master of the Taiji and Qigong.');

# Papers
INSERT INTO paper (title, abstract, filename, reviewer_id, status, comment) VALUES
    ('Autothrottle: A Practical Bi-Level Approach to Resource Management for SLO-Targeted Microservices', 'Achieving resource efficiency while preserving end-user experience is non-trivial for cloud application operators. As cloud applications progressively adopt microservices, resource managers are faced with two distinct levels of system behavior: end-to-end application latency and per-service resource usage. Translating between the two levels, however, is challenging because user requests traverse heterogeneous services that collectively (but unevenly) contribute to the end-to-end latency. We present Autothrottle, a bi-level resource management framework for microservices with latency SLOs (service-level objectives). It architecturally decouples application SLO feedback from service resource control, and bridges them through the notion of performance targets. Specifically, an application-wide learning-based controller is employed to periodically set performance targets—expressed as CPU throttle ratios—for per-service heuristic controllers to attain. We evaluate Autothrottle on three microservice applications, with workload traces from production scenarios. Results show superior CPU savings, up to 26.21% over the best-performing baseline and up to 93.84% over all baselines.', 'ndsi24-1.pdf', 10, 'A', 'Very good job.'),
    ('Jolteon: Unleashing the Promise of Serverless for Serverless Workflows', 'Serverless computing promises automatic resource provisioning to relieve the burden of developers. Yet, developers still have to manually configure resources on current serverless platforms to satisfy application-level requirements. This is because cloud applications are orchestrated as serverless workflows with multiple stages, exhibiting a complex relationship between resource configuration and application requirements.We propose Jolteon, an orchestrator to unleash the promise of automatic resource provisioning for serverless workflows. At the core of Jolteon is a stochastic performance model that combines the benefits of whitebox modeling to capture the execution characteristics of serverless computing and blackbox modeling to accommodate the inherent performance variability. We formulate a chance constrained optimization problem based on the performance model, and exploit sampling and convexity to find optimal resource configurations that satisfy user-defined cost or latency bounds. We implement a system prototype of Jolteon and evaluate it on AWS Lambda with a variety of serverless workflows. The experimental results show that Jolteon outperforms the state-of-the-art solution, Orion, by up to 2.3× on cost and 2.1× on latency.', 'nsdi24-2.pdf', 11, 'A', 'I think it is meaningful.'),
    ('Can''t Be Late: Optimizing Spot Instance Savings under Deadlines', 'Cloud providers offer spot instances alongside on-demand instances to optimize resource utilization. While economically appealing, spot instances’ preemptible nature causes them ill-suited for deadline-sensitive jobs. To allow jobs to meet deadlines while leveraging spot instances, we propose a simple idea: use on-demand instances judiciously as a backup resource. However, due to the unpredictable spot instance availability, determining when to switch between spot and on-demand to minimize cost requires careful policy design. In this paper, we first provide an in-depth characterization of spot instances (e.g., availability, pricing, duration), and develop a basic theoretical model to examine the worst and average-case behaviors of baseline policies (e.g., greedy). The model serves as a foundation to motivate our design of a simple and effective policy, Uniform Progress, which is parameter-free and requires no assumptions on spot availability. Our empirical study, based on three-month-long real spot availability traces on AWS, demonstrates that it can (1) outperform the greedy policy by closing the gap to the optimal policy by 2× in both average and bad cases, and (2) further reduce the gap when limited future knowledge is given. These results hold in a variety of conditions ranging from loose to tight deadlines, low to high spot availability, and on single or multiple instances. By implementing this policy on top of SkyPilot, an intercloud broker system, we achieve 27%-84% cost savings across a variety of representative real-world workloads and deadlines. The spot availability traces are open-sourced for future research.', 'nsdi24-3.pdf', 12, 'A', 'I appreciate this work.'),
    ('Towards Intelligent Automobile Cockpit via A New Container Architecture', 'An intelligent cockpit is now crucial in automobiles, not just to provide digital instrumentation and in-vehicle controls but also to offer a wide range of entertainment functionalities. To cater to the demands of these intelligent vehicles, the automotive industry starts employing virtualization technology to offer a unified hardware and software architecture that can simplify system management and enhance resource utilization. Particularly in the domain of intelligent cockpits, virtualization can tightly integrate systems with different criticality levels (e.g., safety and real-time) on a single hardware platform, improving inter-system communication quality and the timely response to user-initiated requests. Currently, microhypervisor virtualization has been used in production to achieve intelligent automobile cockpit. However, in addition to the performance concern and high production costs, this solution is suffering from the global shortage of chips capable of running microhypervisor systems. Our key insight is that, most functions within intelligent cockpit systems are non-safety-critical and non-real-time multimedia tasks. Based on this characteristic, in this paper we present AutoVP, a new cockpit virtualization architecture. The hardware foundation of AutoVP consists of two low-cost chips: 1) a consumer-grade System-on-Chip (SoC) multi-core processor as the main chip; 2) a typical automotive-grade Microcontroller Unit (MCU) as the auxiliary chip. The MCU auxiliary chip is responsible for hosting real-time and safety-critical tasks, while the SoC main chip primarily handles multimedia tasks, such as entertainment systems and digital instrumentation. Further more, we construct an Android container virtual environment on the SoC main chip. This environment integrates multiple media functions onto a single chip, resulting in efficient utilization of chip computational resources and high system scalability. Our comparative performance evaluation demonstrates that AutoVP is a cost-effective and efficient solution to build intelligent cockpits.', 'nsdi24-4.pdf', 13, 'P', 'We need more details.'),
    ('MuCache: A General Framework for Caching in Microservice Graphs', 'This paper introduces MuCache, a framework for extending arbitrary microservice applications with inter-service caches. MuCache significantly improves the performance of microservice graphs (commonly found in large applications like Uber or Twitter) by eliminating the need for one microservice to call another when the relevant state has not changed. MuCache is enabled by a novel non-blocking cache coherence and invalidation protocol for graph topologies that minimizes critical-path overhead. For this protocol, we prove a strong correctness result: any execution observed by the cache-enabled microservice application could have been observed by the original application without caches. Our evaluation on well-known microservice benchmarks shows that MuCache reduces the median request latency by up to 2.5×, and increases throughput by up to 60%.', 'nsdi24-5.pdf', 14, 'P', 'I need to learn more about your work.'),
    ('A large-scale deployment of DCTCP', 'This paper describes the process and operational experiences of deploying the Data Center TCP (DCTCP) protocol in a large-scale data center network. In contrast to legacy congestion control protocols that rely on loss as the primary signal of congestion, DCTCP signals in-network congestion (based on queue occupancy) to senders and adjusts the sending rate proportional to the level of congestion. At the time of our deployment, this protocol was well-studied and fairly established with proven efficiency gains in other networks. As expected, we also observed improved performance, and notably decreased packet losses, compared to legacy protocols in our data centers. Perhaps unexpectedly, however, we faced numerous hurdles in rolling out DCTCP; we chronicle these unexpected challenges, ranging from its unfairness (to other classes of traffic) to implementation bugs. We close by discussing some of the open research questions and challenges.', 'nsdi24-6.pdf', 15, 'R', 'It is a pity to reject your paper.'),
    ('A Case for a Network Protocol Isolation Layer', 'Network protocols are a critical component of modern distributed systems, but they are often implemented in monolithic network stacks that are difficult to manage and evolve. We argue for a network protocol isolation layer (NPIL) that separates the network protocol implementation from the rest of the network stack. NPIL provides a clean interface for network protocols to interact with the network stack, enabling independent development, testing, and deployment of network protocols. We present the design and implementation of NPIL, and demonstrate its benefits through a case study of implementing QUIC, a modern transport protocol, on top of NPIL. Our evaluation shows that NPIL can improve the development and deployment of network protocols, and that it can be implemented with low overhead.', 'nsdi24-7.pdf', 17, 'R', 'Totally useless.');

# Publishes
INSERT INTO publishes (usr_id, paper_id) VALUES
    (1, 1),
    (1, 3),
    (1, 7),
    (2, 1),
    (2, 3),
    (3, 2),
    (4, 4),
    (4, 5),
    (5, 6),
    (6, 6),
    (7, 2),
    (8, 7);

# Sections
INSERT INTO section (title) VALUES
    ('General'),
    ('AI'),
    ('Networks'),
    ('Architecture'),
    ('Cryptography');

# Posts
INSERT INTO post (title, content, sec_id, pub_id) VALUES
    ('download.sh didn''t work well', 'run download.sh directly, it could download USE_POLICY.md、tokenizer.model successfully, but failed to download tokenizer_checklist.chk', 2, 1),
    ('Llama2 Error while converting model weights to run with Hugging Face', 'I''m following steps listed here https://ai.meta.com/blog/5-steps-to-getting-started-with-llama-2/ I''ve been able to complete couple of steps from this. However, while trying to follow "convert the model weights to run with Hugging Face" step, getting the following error.', 2, 2),
    ('Analysis of loss spikes in LLaMA pretrain', 'A huge thank you for making your remarkable work available to the public! I''ve taken a close look at the pretraining loss curves depicted in Figure 1 of LLaMA [1] and in Figure 5 of LLaMA2 [2]. I found that the LLaMA graph shows several spikes in loss, yet LLaMA2''s curve appears seamlessly smooth.', 2, 8),
    ('How to access Llama v1 weights?', 'Hello. I will use llava-med and it requires llama v1 7B weights. I already filled the form however there is no any notification. It has been over a week and I am still waiting. How can I obtain llama v1 7B weights?', 2, 14),
    ('Cannot Get the Model', 'As a PhD student, I have applied to access the llama model and I couldn''t get any response for nearly a week. In the Hugging Face, it says " Requests will be processed in 1-2 days.". My Hugging Face email and email that I wrote down on the Meta website is the same. So, is there any problem for accessing meta-llama/Llama-2-7b ?', 2, 7),
    ('How to obtain the hidden state of the last layer of Llama2 after calling the chat_completion method?', 'I''ve been thinking about how to obtain the hidden state of the last layer of Llama2 after calling the chat_completion method, but I''m not sure how to implement it. I hope to get some answers.', 2, 3),
    ('Mislead category about networking.', 'Hi, in category Networking, there are 3 awesome, but there NOT same things.', 1, 4),
    ('Add a Natural Science theme?', 'I''ve found many Natural Science related packages in the Miscellaneous theme. Ex:  Neuroscience Bioinformatics Cheminformatics Neuroscience Biomedical Information Extraction In #1213 adding a Natural Science theme was suggested, but eventually closed because of not activity. Should I proceed and add this new theme?', 1, 10),
    ('Replace SQL Write "Master-Slave" in Main Diamgram with more appropriate term', 'Let''s replace the term Master-Slave from this diagram with more appropriate terms suggested here: https://learn.microsoft.com/en-us/style-guide/a-z-word-list-term-collections/m/master-slave  Simple fix: Replace every use of the word master with manager and slave with worker.', 1, 16),
    ('The link for the no-SQL section is broken.  here is the section: No SQL', 'The link for the no-SQL section is broken.  here is the section: No SQL', 1, 13),
    ('Job controller reports the count of terminating pods with unnecessary delay', 'When Job controller is terminating and deletes all pods the counter in the status.terminating field does not reflect this properly.', 3, 9),
    ('Ephemeral volume scheduling problems', 'I have two ephemeral volumes, one that requires 100M of memory and one that requires 43G of memory.', 3, 1),
    ('kubelet crash loop panic with SIGSEGV', 'I was running some pods on my node as usual. At some point (23:41:35.127989 in the log), the kubelet crashed and then went into a crash loop.  Log showing the first crash and several thereafter: kubelet-crash.txt  The errors I see shortly before the crash are', 3, 1),
    ('kubectl cp a file from a Windows Pod to Windows 11 localhost failed', 'I was trying to cp a from a Windows Pod to the Windows localhost. But it failed.  kubectl.exe cp --kubeconfig .\kubconfig -n namespace-win pod-20240509-120334-779546rrfsc:C:\\data\\0509-1065.log 0509-1065.log It showed  tar: Removing leading drive letter from member names error: tar contents corrupted', 3, 2),
    ('Sstc description hasn''t been merged well', 'In this chapter:  Chapter 16. "Sstc" Extension for Supervisor-mode Timer Interrupts, Version 1.0.0 I don''t think this text should be there anymore  To make it easy to understand the deltas from the current Priv 1.11/1.12 specs, this is written as the actual exact changes to be made to existing paragraphs of Priv spec text (or additional paragraphs within the existing text).', 4, 11),
    ('Do the following PMA changes of implicit PTE access need xFENCE to synchronize?', 'First, I want to ensure PMA of PTE access is permitted to cache them the address translation cache. If the above answer is true, I want to ask the following scenarios whether xFENCE is required to synchronize PMA setting and virtual memory system.', 4, 15),
    ('does Xtvec need to support all invalid adddresses?', 'Quotes from the priv spec:  If mtvec is writable, the set of values the register may hold can vary by implementation.  The BASE field in stvec is a field that can hold any valid virtual or physical address, subject to the following alignment constraints  mepc is a WARL register that must be able to hold all valid virtual addresses. It need not be capable of holding all possible invalid addresses.  sepc is a WARL register that must be able to hold all valid virtual addresses. It need not be capable of holding all possible invalid addresses.  If mtval is not read-only zero, it is a WARL register that must be able to hold all valid virtual addresses and the value zero. It need not be capable of holding all possible invalid addresses.  stval is a WARL register that must be able to hold all valid virtual addresses and the value 0. It need not be capable of holding all possible invalid addresses  I''m trying to understand whether mtvec/stvec can be trimmed to only store valid virtual addresses.  The mtvec statement above is ambiguous and doesn''t match the stvec statement, I don''t know any they would be different.  The other registers: mepc, sepc, mtval, stval are specified consistently.  Can we have the same text for all of them? Is there a reason why mtvec/stvec need to be able to store more address bits than the others?', 4, 1),
    ('Userspace unique CPU identifier', 'When optimizing __vdso_getcpu, we need an userspace unique identifier as the CPU id. Currently we just invoke the syscall.', 4, 14),
    ('Talk about the academic morality of professor Tianren Li', 'I am W.Snakeman, I want to take this place to talk about the academic morality of professor Tianren Li. Last fall, I joined his group and conducted a series of research in cryptography, and he promised to accept me as his Ph.D. However, he rejected me just a few days ago for his laziness. I think it is really not a human thing.', 5, 5),
    ('How to access Llama v1 weights?', 'Hello. I will use llava-med and it requires llama v1 7B weights. I already filled the form however there is no any notification. It has been over a week and I am still waiting. How can I obtain llama v1 7B weights?', 5, 14),
    ('Cannot Get the Model', 'As a PhD student, I have applied to access the llama model and I couldn''t get any response for nearly a week. In the Hugging Face, it says " Requests will be processed in 1-2 days.". My Hugging Face email and email that I wrote down on the Meta website is the same. So, is there any problem for accessing meta-llama/Llama-2-7b ?', 5, 7),
    ('How to obtain the hidden state of the last layer of Llama2 after calling the chat_completion method?', 'I''ve been thinking about how to obtain the hidden state of the last layer of Llama2 after calling the chat_completion method, but I''m not sure how to implement it. I hope to get some answers.', 5, 3);

# Replies
INSERT INTO reply (content, post_id, pub_id) VALUES
    ('Have no idea but maybe you could try delete the whole repo and git clone it again. The first time I ran download.sh it just says ERROR 403: Forbidden. like the last line of your error message, after I delete the whole repo and git clone it again it works quite well.', 1, 12),
    ('Tried but doesn''t work. does it mean we can''t download the model in China ?', 1, 1),
    ('Don''t think so. I deployed it on remote server in my school and there wasn''t VPN or proxy or something like that on the device, but it worked.', 1, 12),
    ('Could you try directly running the command without the " --llama_version 2" as that may not be a valid argument', 2, 5),
    ('Thank you for sharing your input. However, there is no difference in the output. I had given this parameter after checking the source code in convert_llama_weights_to_hf.py. The reason of providing this parameter was: "I thought that by giving the model version the script may work and the JSON error may go away"', 2, 2),
    ('I am not able to reproduce the issue on my side. Could you please provide the exact steps you followed and the entire stack trace? Thanks!', 2, 5),
    ('I had followed the exact steps listed here https://ai.meta.com/blog/5-steps-to-getting-started-with-llama-2/', 2, 2),
    ('Thank you. Could you check if the params.json file is in the same directory as the model you are trying to convert, and that it''s called exactly params.json? Also, could you double check if the json is a valid json file and not malformed?', 2, 5),
    ('The difference observed in the pretraining loss curves between LLaMA and LLaMA2 could be due to various factors: Improved Training Techniques: LLaMA2 might have benefited from advancements or refinements in training techniques compared to LLaMA. These improvements could lead to smoother loss curves and more stable training. Different Architectures or Hyperparameters: LLaMA2 may have used different model architectures or hyperparameters compared to LLaMA, resulting in smoother convergence during training. Data Variability: The datasets used for pretraining LLaMA and LLaMA2 might have had different characteristics or levels of noise. A more varied or noisy dataset could result in a loss curve with more fluctuations. Data Processing or Augmentation: Differences in data preprocessing or augmentation techniques between LLaMA and LLaMA2 could also influence the smoothness of the loss curves. Graphical Representation: It''s also possible that the smoothing applied to the visualization of the loss curve in LLaMA2 might differ from that of LLaMA, leading to the appearance of a smoother curve.', 3, 1),
    ('Moving this to meta-llama/llama as this touched the original paper.', 3, 10),
    ('Hello, I have encountered the same problem. I have been sending the request for a week now. Have you received a reply?', 4, 3),
    ('Hi, yeap I downloaded it from unofficial link that I found on another ones repo. I think it is not appropriate to share the link here but you can find it if you google it more.', 4, 14),
    ('Hi @mntalha I tried downloading today using this link https://llama.meta.com/llama-downloads/ then I instantly got the mail on how to move forward with its download !', 5, 1),
    ('Hi, Interesting, which models did you choose to access? I chose all in my application.', 5, 7),
    ('Hello Same even I chose all the models !', 5, 1),
    ('Please try again and let us know if it doesn''t work. We are trying to streamline the approval process so it should be a lot faster.', 5, 16),
    ('Hi! I am able to download the llama2 models directly via the email/meta release form, but have not gotten HF approval. The emails I used are the same (zche@umd.edu). The HF repo I''m requesting access to is Llama-2-7b-chat-hf. I can''t resubmit a HF access request. It''s been a while (~a month?) since my HF request. Could you help me troubleshoot this?', 5, 16),
    ('Thank you, I received an email by Meta and installed the model successfully.', 5, 7),
    ('any answer? I meet the same question.', 6, 12),
    ('I think you can overwirte model to get the hidden state.', 6, 3),
    ('Have you implemented it? Would you mind sharing the code?', 6, 12),
    ('I lost my code. I can share my thought to you. During debugging, you can identify one hidden state to map to a vocabulary size of 32000. That should be the hidden state of the last layer of Llama2.', 6, 3),
    ('Thanks for your kind reply~', 6, 12),
    ('Good', 7, 1),
    ('Do you need assistance?', 7, 13),
    ('I love to be your assistance', 7, 5),
    ('It doesn''t appear this went update was made, but I would say Parasite would also fall under this header.', 8, 2),
    ('Java is a widely used object-oriented programming language and software platform that runs on billions of devices, including notebook computers, mobile devices, gaming consoles, medical devices and many others. The rules and syntax of Java are based on the C and C++ languages.', 8, 17),
    ('better u add parasite under header', 8, 12),
    ('Replace the text in all the images ?', 9, 11),
    ('Is ''Dominant'' and ''Submissive'' allowed? ', 9, 6),
    ('I''d like to work on this issue, can you explain me where the link is broken, that is in either documentation or somewhere else.', 10, 1),
    ('The link is in the No SQL section. Is the one labeled as ''redis architecture''', 10, 7),
    ('Can you assign this issue to me, and share the link for redis architecture', 10, 9),
    ('/assign', 11, 11),
    ('important-longterm', 11, 12),
    ('I looks like the analogous situation is inside manageJob, for example when suspending a job here, we update the active count, but not terminating, so the terminating counter is lagging behind as the events propagate.', 11, 5),
    ('This issue is currently awaiting triage.  If a SIG or subproject determines this is a relevant issue, they will accept it by applying the triage/accepted label and provide further guidance.  The triage/accepted label can be added by org members by writing /triage accepted in a comment.', 12, 14),
    ('as a workaround, can you combine the two volumes and use subpath for different mounts? Does localcsi driver support storage capacity tracking? If it relies on that feature, enhancement is still needed as it currently only supports one PVC per Pod.', 12, 8),
    ('Thank you for your reply. I''ll think about this solution.', 12, 1),
    ('errors.As will panic if target is not a non-nil pointer to either a type that implements error, or to any interface type. As returns false if err is nil. But syscall.Errno clearly implements error.', 13, 15),
    ('According to the changelog, kubernentes v1.28.6 (what I''m using) is built with go 1.21.7', 13, 5),
    ('do you have a more succinct reproducer to make it easier to find the issue?', 13, 4),
    ('Not really sorry. The only weird thing which may be relevant: This happened on a control plane node, and I didn''t have any taints on my control plane nodes, so it was running normal pods as well as control plane pods. No idea if that''s relevant.', 13, 1),
    ('windows', 14, 1),
    ('Try this way kubectl.exe cp --kubeconfig .\kubconfig -n namespace-win pod-20240509-120334-779546rrfsc:C:/data/0509-1065.log ./0509-1065.log', 14, 1),
    ('It failed. It shows', 14, 2),
    ('maybe it should be a different issue, but this is redundant too:', 15, 1),
    ('I believe @gfavor is aware that one of the many, many things on his to-do list is to better integrate the Sstc chapter. (Sstc is certainly not the only offender in this regard.)', 15, 5),
    ('the architecture), and PMAs are managed by M-mode firmware, it is up to that implementation-specific firmware to do any necessary sfence''ing when PMAs are changed.  This is true for all memory accesses, not just PTE memory accesses.', 16, 7),
    ('Configurable PMAs are custom and implementation defined, not defined by the spec, so I suspect there is a "correct" answer.', 16, 9),
    ('OK, got it. Thanks a lot.', 16, 15),
    ('My understanding is that mtvec can be hardwired to one specific value if you want (e.g. the handler is in ROM). So it doesn''t need to support all invalid addresses or even all valid addresses. The others need to support all valid addresses.', 17, 3),
    ('No, the constraints on mepc and mtval are inherently a little different from mtvec. Indeed it''s not useful for mtvec to be able to hold invalid addresses. But it is important that mepc and mtval hold at least one invalid address, to indicate the reason for an exception is that the address is invalid (as opposed to being valid but currently faulting).', 17, 16),
    ('ok - thanks - so the rationale is that mtvec doesn''t need to be able to hold any invalid addresses whereas mepc and the others must store at least one.', 17, 1),
    ('A fine summary of the discussion.', 17, 12),
    ('Ping for comments.', 18, 14),
    ('No, there is no plan to add such a feature.', 18, 1),
    ('If so, then there is no meaning for getcpu in vDSO, which may cause some performance issues compared to other archs. What if we add an extension to expose mhartid to unprivileged code?', 18, 14),
    ('There is a reason to have getcpu in the vDSO, which is that a user-space facility could eventually be added if deemed necessary. Perhaps its day will come.', 18, 1),
    ('I agree with you. Tianren Li is a bad guy and we should not trust him or accept his papers.', 19, 1),
    ('I think what this post says is not true. I have been working with Tianren Li for a long time and I think he is a good guy.', 19, 5),
    ('I think this post is not appropriate. We should not talk about personal issues here.', 19, 7),
    ('I agree with you. We should not talk about personal issues here.', 19, 16),
    ('Hello, I have encountered the same problem. I have been sending the request for a week now. Have you received a reply?', 20, 3),
    ('Hi, yeap I downloaded it from unofficial link that I found on another ones repo. I think it is not appropriate to share the link here but you can find it if you google it more.', 20, 14),
    ('Hi @mntalha I tried downloading today using this link https://llama.meta.com/llama-downloads/ then I instantly got the mail on how to move forward with its download !', 21, 1),
    ('Hi, Interesting, which models did you choose to access? I chose all in my application.', 21, 7),
    ('Hello Same even I chose all the models !', 21, 1),
    ('Please try again and let us know if it doesn''t work. We are trying to streamline the approval process so it should be a lot faster.', 21, 16),
    ('Hi! I am able to download the llama2 models directly via the email/meta release form, but have not gotten HF approval. The emails I used are the same (zche@umd.edu). The HF repo I''m requesting access to is Llama-2-7b-chat-hf. I can''t resubmit a HF access request. It''s been a while (~a month?) since my HF request. Could you help me troubleshoot this?', 21, 16),
    ('Thank you, I received an email by Meta and installed the model successfully.', 21, 7),
    ('any answer? I meet the same question.', 22, 12),
    ('I think you can overwirte model to get the hidden state.', 22, 3),
    ('Have you implemented it? Would you mind sharing the code?', 22, 12),
    ('I lost my code. I can share my thought to you. During debugging, you can identify one hidden state to map to a vocabulary size of 32000. That should be the hidden state of the last layer of Llama2.', 22, 3),
    ('Thanks for your kind reply~', 22, 12);
